{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.datasets.fashion_mnist import load_data\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = TensorBoard(log_dir='./fashion_mnist_logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "        0: \"T-shirt/top\", 1:\"Trouser\", 2:\"Pullover\", 3:\"Dress\",  4:\"Coat\", \n",
    "        5:\"Sandal\",  6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(index):\n",
    "        plt.imshow(x_train[index], cmap=\"gray\")\n",
    "        plt.title(labels[y_train[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert type and normalize to (0,1)\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data from (60000, 28, 28) to (60000, 784)\n",
    "x_train_flatten = x_train.reshape(60000, 28*28)\n",
    "x_test_flatten = x_test.reshape(10000, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Just your regular densely-connected NN layer.\n",
       "\n",
       "`Dense` implements the operation:\n",
       "`output = activation(dot(input, kernel) + bias)`\n",
       "where `activation` is the element-wise activation function\n",
       "passed as the `activation` argument, `kernel` is a weights matrix\n",
       "created by the layer, and `bias` is a bias vector created by the layer\n",
       "(only applicable if `use_bias` is `True`).\n",
       "\n",
       "Note: if the input to the layer has a rank greater than 2, then\n",
       "it is flattened prior to the initial dot product with `kernel`.\n",
       "\n",
       "Example:\n",
       "\n",
       "```python\n",
       "    # as first layer in a sequential model:\n",
       "    model = Sequential()\n",
       "    model.add(Dense(32, input_shape=(16,)))\n",
       "    # now the model will take as input arrays of shape (*, 16)\n",
       "    # and output arrays of shape (*, 32)\n",
       "\n",
       "    # after the first layer, you don't need to specify\n",
       "    # the size of the input anymore:\n",
       "    model.add(Dense(32))\n",
       "```\n",
       "\n",
       "Arguments:\n",
       "    units: Positive integer, dimensionality of the output space.\n",
       "    activation: Activation function to use.\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
       "    bias_initializer: Initializer for the bias vector.\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix.\n",
       "    bias_regularizer: Regularizer function applied to the bias vector.\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\")..\n",
       "    kernel_constraint: Constraint function applied to\n",
       "        the `kernel` weights matrix.\n",
       "    bias_constraint: Constraint function applied to the bias vector.\n",
       "\n",
       "Input shape:\n",
       "    nD tensor with shape: `(batch_size, ..., input_dim)`.\n",
       "    The most common situation would be\n",
       "    a 2D input with shape `(batch_size, input_dim)`.\n",
       "\n",
       "Output shape:\n",
       "    nD tensor with shape: `(batch_size, ..., units)`.\n",
       "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
       "    the output would have shape `(batch_size, units)`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.virtualenvs/tf3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/core.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(100, input_shape=(784,), activation=\"relu\"))\n",
    "model1.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=\"sgd\",\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vector to binary class matrices\n",
    "y_train_class = to_categorical(y_train, 10)\n",
    "y_test_class = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.2 µs\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3073 - acc: 0.8921 - val_loss: 0.3516 - val_acc: 0.8782\n",
      "\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3064 - acc: 0.8938 - val_loss: 0.3524 - val_acc: 0.8775\n",
      "\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3058 - acc: 0.8933 - val_loss: 0.3518 - val_acc: 0.8777\n",
      "\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3051 - acc: 0.8933 - val_loss: 0.3503 - val_acc: 0.8780\n",
      "\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.3041 - acc: 0.8937 - val_loss: 0.3515 - val_acc: 0.8765\n",
      "\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.3027 - acc: 0.8946 - val_loss: 0.3509 - val_acc: 0.8789\n",
      "\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3026 - acc: 0.8948 - val_loss: 0.3558 - val_acc: 0.8760\n",
      "\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.3020 - acc: 0.8947 - val_loss: 0.3524 - val_acc: 0.8778\n",
      "\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.3014 - acc: 0.8946 - val_loss: 0.3498 - val_acc: 0.8772\n",
      "\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.3001 - acc: 0.8955 - val_loss: 0.3498 - val_acc: 0.8781\n",
      "\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.3000 - acc: 0.8953 - val_loss: 0.3489 - val_acc: 0.8780\n",
      "\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 22us/step - loss: 0.2985 - acc: 0.8955 - val_loss: 0.3484 - val_acc: 0.8776\n",
      "\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2979 - acc: 0.8958 - val_loss: 0.3489 - val_acc: 0.8780\n",
      "\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2974 - acc: 0.8962 - val_loss: 0.3480 - val_acc: 0.8786\n",
      "\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2968 - acc: 0.8959 - val_loss: 0.3531 - val_acc: 0.8760\n",
      "\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2960 - acc: 0.8969 - val_loss: 0.3475 - val_acc: 0.8775\n",
      "\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2952 - acc: 0.8966 - val_loss: 0.3459 - val_acc: 0.8787\n",
      "\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2942 - acc: 0.8975 - val_loss: 0.3484 - val_acc: 0.8795\n",
      "\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2935 - acc: 0.8980 - val_loss: 0.3485 - val_acc: 0.8772\n",
      "\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2931 - acc: 0.8970 - val_loss: 0.3510 - val_acc: 0.8779\n",
      "\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2920 - acc: 0.8976 - val_loss: 0.3463 - val_acc: 0.8804\n",
      "\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2915 - acc: 0.8984 - val_loss: 0.3502 - val_acc: 0.8786\n",
      "\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2909 - acc: 0.8973 - val_loss: 0.3460 - val_acc: 0.8793\n",
      "\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2903 - acc: 0.8991 - val_loss: 0.3433 - val_acc: 0.8787\n",
      "\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2895 - acc: 0.8978 - val_loss: 0.3501 - val_acc: 0.8785\n",
      "\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2889 - acc: 0.8991 - val_loss: 0.3468 - val_acc: 0.8779\n",
      "\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2884 - acc: 0.8992 - val_loss: 0.3441 - val_acc: 0.8813\n",
      "\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2868 - acc: 0.8995 - val_loss: 0.3450 - val_acc: 0.8813\n",
      "\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2868 - acc: 0.8996 - val_loss: 0.3435 - val_acc: 0.8808\n",
      "\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2860 - acc: 0.8995 - val_loss: 0.3476 - val_acc: 0.8793\n",
      "\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2854 - acc: 0.9003 - val_loss: 0.3446 - val_acc: 0.8801\n",
      "\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2850 - acc: 0.9003 - val_loss: 0.3475 - val_acc: 0.8773\n",
      "\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2840 - acc: 0.9003 - val_loss: 0.3537 - val_acc: 0.8758\n",
      "\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2835 - acc: 0.9000 - val_loss: 0.3444 - val_acc: 0.8800\n",
      "\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2833 - acc: 0.9001 - val_loss: 0.3423 - val_acc: 0.8803\n",
      "\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2823 - acc: 0.9012 - val_loss: 0.3434 - val_acc: 0.8813\n",
      "\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2819 - acc: 0.9011 - val_loss: 0.3416 - val_acc: 0.8796\n",
      "\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2818 - acc: 0.9015 - val_loss: 0.3434 - val_acc: 0.8793\n",
      "\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2808 - acc: 0.9016 - val_loss: 0.3418 - val_acc: 0.8795\n",
      "\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2798 - acc: 0.9028 - val_loss: 0.3455 - val_acc: 0.8799\n",
      "\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2794 - acc: 0.9029 - val_loss: 0.3429 - val_acc: 0.8798\n",
      "\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2784 - acc: 0.9033 - val_loss: 0.3572 - val_acc: 0.8744\n",
      "\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 23us/step - loss: 0.2787 - acc: 0.9026 - val_loss: 0.3413 - val_acc: 0.8809\n",
      "\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2775 - acc: 0.9024 - val_loss: 0.3467 - val_acc: 0.8789\n",
      "\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2770 - acc: 0.9021 - val_loss: 0.3431 - val_acc: 0.8802\n",
      "\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2763 - acc: 0.9036 - val_loss: 0.3401 - val_acc: 0.8814\n",
      "\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2756 - acc: 0.9034 - val_loss: 0.3503 - val_acc: 0.8787\n",
      "\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2751 - acc: 0.9032 - val_loss: 0.3507 - val_acc: 0.8754\n",
      "\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 22us/step - loss: 0.2748 - acc: 0.9035 - val_loss: 0.3410 - val_acc: 0.8816\n",
      "\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 23us/step - loss: 0.2743 - acc: 0.9025 - val_loss: 0.3405 - val_acc: 0.8804\n",
      "\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2738 - acc: 0.9045 - val_loss: 0.3434 - val_acc: 0.8796\n",
      "\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2729 - acc: 0.9048 - val_loss: 0.3400 - val_acc: 0.8806\n",
      "\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2722 - acc: 0.9049 - val_loss: 0.3419 - val_acc: 0.8807\n",
      "\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 23us/step - loss: 0.2717 - acc: 0.9045 - val_loss: 0.3469 - val_acc: 0.8787\n",
      "\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 22us/step - loss: 0.2714 - acc: 0.9050 - val_loss: 0.3410 - val_acc: 0.8802\n",
      "\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2705 - acc: 0.9044 - val_loss: 0.3464 - val_acc: 0.8799\n",
      "\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2700 - acc: 0.9055 - val_loss: 0.3380 - val_acc: 0.8821\n",
      "\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 23us/step - loss: 0.2691 - acc: 0.9064 - val_loss: 0.3441 - val_acc: 0.8811\n",
      "\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2692 - acc: 0.9055 - val_loss: 0.3431 - val_acc: 0.8788\n",
      "\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2682 - acc: 0.9061 - val_loss: 0.3401 - val_acc: 0.8812\n",
      "\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2684 - acc: 0.9052 - val_loss: 0.3438 - val_acc: 0.8781\n",
      "\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2676 - acc: 0.9059 - val_loss: 0.3489 - val_acc: 0.8782\n",
      "\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2671 - acc: 0.9058 - val_loss: 0.3514 - val_acc: 0.8776\n",
      "\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2666 - acc: 0.9071 - val_loss: 0.3423 - val_acc: 0.8812\n",
      "\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2662 - acc: 0.9067 - val_loss: 0.3408 - val_acc: 0.8798\n",
      "\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2655 - acc: 0.9069 - val_loss: 0.3362 - val_acc: 0.8830\n",
      "\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2650 - acc: 0.9066 - val_loss: 0.3368 - val_acc: 0.8830\n",
      "\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2639 - acc: 0.9081 - val_loss: 0.3418 - val_acc: 0.8802\n",
      "\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2641 - acc: 0.9073 - val_loss: 0.3430 - val_acc: 0.8801\n",
      "\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2631 - acc: 0.9074 - val_loss: 0.3390 - val_acc: 0.8817\n",
      "\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2622 - acc: 0.9077 - val_loss: 0.3373 - val_acc: 0.8819\n",
      "\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2625 - acc: 0.9083 - val_loss: 0.3542 - val_acc: 0.8753\n",
      "\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2618 - acc: 0.9090 - val_loss: 0.3388 - val_acc: 0.8812\n",
      "\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2610 - acc: 0.9092 - val_loss: 0.3369 - val_acc: 0.8815\n",
      "\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2605 - acc: 0.9089 - val_loss: 0.3409 - val_acc: 0.8810\n",
      "\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2602 - acc: 0.9082 - val_loss: 0.3383 - val_acc: 0.8818\n",
      "\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2590 - acc: 0.9093 - val_loss: 0.3369 - val_acc: 0.8808\n",
      "\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2590 - acc: 0.9103 - val_loss: 0.3380 - val_acc: 0.8826\n",
      "\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2588 - acc: 0.9090 - val_loss: 0.3336 - val_acc: 0.8837\n",
      "\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2582 - acc: 0.9102 - val_loss: 0.3357 - val_acc: 0.8824\n",
      "\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2574 - acc: 0.9100 - val_loss: 0.3338 - val_acc: 0.8835\n",
      "\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2570 - acc: 0.9104 - val_loss: 0.3337 - val_acc: 0.8837\n",
      "\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2563 - acc: 0.9101 - val_loss: 0.3359 - val_acc: 0.8832\n",
      "\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2561 - acc: 0.9104 - val_loss: 0.3389 - val_acc: 0.8824\n",
      "\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 18us/step - loss: 0.2559 - acc: 0.9095 - val_loss: 0.3414 - val_acc: 0.8797\n",
      "\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2554 - acc: 0.9115 - val_loss: 0.3420 - val_acc: 0.8802\n",
      "\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2550 - acc: 0.9107 - val_loss: 0.3333 - val_acc: 0.8830\n",
      "\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2541 - acc: 0.9115 - val_loss: 0.3348 - val_acc: 0.8825\n",
      "\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2536 - acc: 0.9113 - val_loss: 0.3363 - val_acc: 0.8828\n",
      "\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2534 - acc: 0.9107 - val_loss: 0.3514 - val_acc: 0.8755\n",
      "\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2531 - acc: 0.9120 - val_loss: 0.3394 - val_acc: 0.8814\n",
      "\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2520 - acc: 0.9129 - val_loss: 0.3343 - val_acc: 0.8835\n",
      "\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 19us/step - loss: 0.2522 - acc: 0.9122 - val_loss: 0.3349 - val_acc: 0.8809\n",
      "\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2512 - acc: 0.9129 - val_loss: 0.3376 - val_acc: 0.8829\n",
      "\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2509 - acc: 0.9119 - val_loss: 0.3337 - val_acc: 0.8836\n",
      "\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 24us/step - loss: 0.2508 - acc: 0.9129 - val_loss: 0.3343 - val_acc: 0.8827\n",
      "\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 21us/step - loss: 0.2507 - acc: 0.9128 - val_loss: 0.3324 - val_acc: 0.8830\n",
      "\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2494 - acc: 0.9127 - val_loss: 0.3326 - val_acc: 0.8844\n",
      "\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 20us/step - loss: 0.2483 - acc: 0.9136 - val_loss: 0.3356 - val_acc: 0.8819\n",
      "\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================]48000/48000 [==============================] - 1s 22us/step - loss: 0.2483 - acc: 0.9135 - val_loss: 0.3384 - val_acc: 0.8823\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x131cca748>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "model1.fit(x_train_flatten, y_train_class, batch_size=128, epochs=100, verbose=1, validation_split=0.2, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================]10000/10000 [==============================] - 0s 25us/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(x_test_flatten, y_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36228553161621097, 0.8717]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_array = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\",  \"Coat\", \n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "proba = model1.predict_proba(x_test_flatten)\n",
    "fig = plt.figure(figsize=(4, 6)) \n",
    "plt.subplot(211)\n",
    "plt.imshow(x_test[index], cmap=\"gray\")\n",
    "plt.title(label_array[y_test[index]])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.barh(y=range(len(proba[index])), width=proba[index], tick_label=label_array)\n",
    "plt.xlim(0,1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
